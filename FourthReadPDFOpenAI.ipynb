{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a13016ed-8fb8-4267-a65c-eb26f4e911f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (1.34.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c2373df-cbbc-42b9-9b15-c3e97349acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c41cfe2-7b12-4839-9c07-db269d77c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone-client) (2024.6.2)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone-client) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\prohr\\anaconda3\\envs\\testingopenai\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "892758e4-63da-4754-bdb6-23c15faed9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import PyPDF2\n",
    "import random\n",
    "import pinecone\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbd768d-89aa-45ec-bc1b-7ae8b9dc1549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"XXXX\"\n",
    "client = OpenAI()\n",
    "print(client.models.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0895698-a34c-4c00-af2b-ed36f2a608f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_name):\n",
    "    pdf_file = open(file_name,'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text_content=\"\"\n",
    "    for page in range(len(pdf_reader.pages)):\n",
    "        text_content += pdf_reader.pages[page].extract_text()\n",
    "    pdf_file.close()\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d17d86-cf69-45ca-9833-60e794d598c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text,chunk_size=1500,chunk_overlap=100,by='word'):\n",
    "    if by not in ['word','char']:\n",
    "        raise ValueError(\"Please Insert correct 'by' input, should be word or char\")\n",
    "    chunks = []\n",
    "    if by == 'word':\n",
    "        text = text.split()\n",
    "    elif by == 'char':\n",
    "        text = text\n",
    "    current_chunk_start = 0\n",
    "    while current_chunk_start < len(text):\n",
    "        current_chunk_end = current_chunk_start +  chunk_size\n",
    "        if by == 'word':\n",
    "            chunk = \" \".join(text[current_chunk_start:current_chunk_end])\n",
    "        else:\n",
    "            chunk = text[current_chunk_start:current_chunk_end]\n",
    "\n",
    "        chunks.append(chunk)\n",
    "        current_chunk_start += (chunk_size - chunk_overlap)\n",
    "\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fca4283-308b-4e2c-8ed8-3fd907baa6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loaded = load_pdf(\"C:/Users/prohr/Downloads/state_of_ai_docs.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd10bfaf-9fcc-48e3-8842-6c29dd24ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(pdf_loaded, by='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "152d1563-dde4-446d-866b-295f9cc06113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c491e2b9-0f33-41d6-af33-f02b64fecc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As organizations rapidly deploy generative AI tools, survey respondents \n",
      "expect significant effects on their industries and workforces.The state of AI in \n",
      "2023: Generative AI’s \n",
      "breakout year\n",
      "August 2023The state of AI in 2023: Generative AI’s breakout yearThe latest annual McKinsey Global Survey  on the current  \n",
      "state of AI confirms the explosive growth of generative AI  \n",
      "(gen AI) tools. Less than a year after many of these tools debuted, \n",
      "one-third of our survey respondents say their organizations are \n",
      "using gen AI regularly in at least one business function. Amid \n",
      "recent advances, AI has risen from a topic relegated to tech \n",
      "employees to a focus of company leaders: nearly one-quarter  \n",
      "of surveyed C-suite executives say they are personally using  \n",
      "gen AI tools for work, and more than one-quarter of respondents \n",
      "from companies using AI say gen AI is already on their boards’ \n",
      "agendas. What’s more, 40 percent of respondents say their \n",
      "organizations will increase their investment in AI overall because \n",
      "of advances in gen AI. The findings show that these are still early \n",
      "days for managing gen AI–related risks, with less than half of \n",
      "respondents saying their organizations are mitigating even the \n",
      "risk they consider most relevant: inaccuracy.\n",
      "The organizations that have already embedded AI capabilities \n",
      "have been the first to explore gen AI’s potential, and those seeing \n",
      "the most value from more traditional AI capabilities—a group we \n",
      "call AI high performers—are already outpaci\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    print(chunks[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "557a7bd1-78a3-4d8b-88aa-4c8e369f8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"ABCD\")\n",
    "index = pc.Index(\"Txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2359eb9-5c80-4f5e-970a-47e166635408",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chunks)):\n",
    "    vec = client.embeddings.create(\n",
    "        model= \"text-embedding-ada-002\",\n",
    "        input= chunks[i]\n",
    "    )\n",
    "    vec = vec.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a028b5f9-ade2-457b-bb6c-465da9996089",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_response = index.upsert(\n",
    "    vectors = [\n",
    "     (\n",
    "         str(i),\n",
    "         vec,\n",
    "         {\"chunk_content\" : chunks[i]}\n",
    "     )   \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31520ab7-07b8-4fd5-8871-5fa5553f0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask some question regarding the document:  Recent trend in AI\n"
     ]
    }
   ],
   "source": [
    "user_request = input(\"Ask some question regarding the document: \")\n",
    "\n",
    "user_vector = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=user_request)\n",
    "\n",
    "user_vector = user_vector.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bac1a01d-d184-4f49-b1ca-5c3b5c0e9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'I want you to act as a support agent. Your name is \"My Super Assistant\". You will provide me with answers from the given info. If the answer is not included, say exactly \"Ooops! I don\\'t know that.\" and stop after that. Refuse to answer any question not about the info. Never break character and always answer on the given text.'}, {'role': 'user', 'content': 'nd \\ncapabilities that allow them to generate value. One way to interpret this is that “the rich \\nare getting richer” when it comes to extracting value from AI. We’ll be interested in seeing \\nwhether the great interest in generative AI opens the door to higher overall adoption of AI \\ngoing forward.\\n21\\nThe state of AI in 2023: Generative AI’s breakout yearQuantumBlack AI, by McKinsey  \\nAugust 2023  \\nCopyright © McKinsey & Company  \\nDesigned by McKinsey Global Publishing\\nMcKinsey.com\\n @McKinsey  \\n  @McKinsey\\nScan • Download • Personalize\\nFind more content like this on the \\nMcKinsey Insights App'}, {'role': 'user', 'content': 'Recent trend in AI'}]\n"
     ]
    }
   ],
   "source": [
    "matches = index.query(\n",
    "    vector=user_vector,\n",
    "    top_k=1,\n",
    "    include_metadata=True,\n",
    "    )\n",
    "\n",
    "messages = [{\"role\" : \"system\", \"content\":\"\"\"I want you to act as a support agent. Your name is \"My Super Assistant\". You will provide me with answers from the given info. If the answer is not included, say exactly \"Ooops! I don't know that.\" and stop after that. Refuse to answer any question not about the info. Never break character and always answer on the given text.\"\"\"}]\n",
    "messages.append({\"role\":\"user\",\"content\": matches['matches'][0]['metadata']['chunk_content']})\n",
    "messages.append({\"role\":\"user\",\"content\":user_request})\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e094d1f-3a84-4c63-9064-73c420ecace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The recent trend in AI is the rise of Generative AI, which is expected to have a breakout year in 2023 according to QuantumBlack AI by McKinsey.\n",
      "\n",
      "Context:  nd \n",
      "capabilities that allow them to generate value. One way to interpret this is that “the rich \n",
      "are getting richer” when it comes to extracting value from AI. We’ll be interested in seeing \n",
      "whether the great interest in generative AI opens the door to higher overall adoption of AI \n",
      "going forward.\n",
      "21\n",
      "The state of AI in 2023: Generative AI’s breakout yearQuantumBlack AI, by McKinsey  \n",
      "August 2023  \n",
      "Copyright © McKinsey & Company  \n",
      "Designed by McKinsey Global Publishing\n",
      "McKinsey.com\n",
      " @McKinsey  \n",
      "  @McKinsey\n",
      "Scan • Download • Personalize\n",
      "Find more content like this on the \n",
      "McKinsey Insights App\n",
      "$$$$$\n"
     ]
    }
   ],
   "source": [
    "chat_response  = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=400 \n",
    ")\n",
    "\n",
    "messages.append({\"role\":\"assistant\",\"content\":chat_response.choices[0].message.content})\n",
    "print(\"Assistant:\", chat_response.choices[0].message.content)\n",
    "print()\n",
    "print(\"Context: \", matches['matches'][0]['metadata']['chunk_content'])\n",
    "print(\"$$$$$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de67d9-b346-4569-bc48-943cc5c5b6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
